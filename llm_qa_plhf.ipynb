{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dave-does-data/llm-qa-rlhf/blob/main/llm_qa_plhf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r llm-qa-rlhf\n",
        "! git clone https://github.com/dave-does-data/llm-qa-rlhf.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4YsW0kmUU0m",
        "outputId": "9beafbf3-ef50-4684-ee37-747c18b2f350"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llm-qa-rlhf'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 60 (delta 22), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (60/60), 26.72 KiB | 3.82 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "62mgWR1fQ94z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/dave-does-data/llm-qa-rlhf.git\n",
        "!pip install -r llm-qa-rlhf/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgo594cZnoTr",
        "outputId": "c2c34c09-9534-498c-aeb0-6143bae89b6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "I-7TCRQpVaJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "182017da-3117-4e72-e451-1a39b829f45c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdave-does-data\u001b[0m (\u001b[33mutsa-it-phd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp llm-qa-rlhf/src/trl/sft_trainer.py .\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0bh_x3aSMA4",
        "outputId": "2e09dced-f033-45ec-cad4-a8cc77f2105f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llm-qa-rlhf  __pycache__  sample_data  sft_trainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llm-qa-rlhf/src/trl/sft_trainer.py \\\n",
        "    --model_name meta-llama/Llama-2-7b-hf \\\n",
        "    --dataset_name dave-does-data/databricks-dolly-qa-subset-7k \\\n",
        "    --log_with 'wandb' \\\n",
        "    --logging_steps 1 \\\n",
        "    --load_in_8bit \\\n",
        "    --use_peft \\\n",
        "    --batch_size 4 \\\n",
        "    --gradient_accumulation_steps 4 \\\n",
        "    --max_steps 250"
      ],
      "metadata": {
        "id": "M86KHvVXgxzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84996545-df66-4dc7-a884-c34746afcc69"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-29 02:22:32.517255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100% 2/2 [01:14<00:00, 37.05s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "Using pad_token, but it is not set yet.\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdave-does-data\u001b[0m (\u001b[33mutsa-it-phd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.7 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230729_022406-d56a5i14\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpious-tree-9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/utsa-it-phd/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/utsa-it-phd/huggingface/runs/d56a5i14\u001b[0m\n",
            "  0% 0/250 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 2.1927, 'learning_rate': 1.40436e-05, 'epoch': 0.0}\n",
            "{'loss': 2.3582, 'learning_rate': 1.39872e-05, 'epoch': 0.0}\n",
            "{'loss': 2.3391, 'learning_rate': 1.39308e-05, 'epoch': 0.01}\n",
            "{'loss': 2.3074, 'learning_rate': 1.38744e-05, 'epoch': 0.01}\n",
            "{'loss': 2.1384, 'learning_rate': 1.3818e-05, 'epoch': 0.01}\n",
            "{'loss': 2.247, 'learning_rate': 1.37616e-05, 'epoch': 0.01}\n",
            "{'loss': 2.0936, 'learning_rate': 1.37052e-05, 'epoch': 0.01}\n",
            "{'loss': 2.3152, 'learning_rate': 1.36488e-05, 'epoch': 0.02}\n",
            "{'loss': 2.0619, 'learning_rate': 1.35924e-05, 'epoch': 0.02}\n",
            "{'loss': 1.9475, 'learning_rate': 1.3536e-05, 'epoch': 0.02}\n",
            "{'loss': 2.1536, 'learning_rate': 1.34796e-05, 'epoch': 0.02}\n",
            "{'loss': 2.3069, 'learning_rate': 1.34232e-05, 'epoch': 0.02}\n",
            "{'loss': 2.4061, 'learning_rate': 1.33668e-05, 'epoch': 0.03}\n",
            "{'loss': 2.127, 'learning_rate': 1.33104e-05, 'epoch': 0.03}\n",
            "{'loss': 2.0894, 'learning_rate': 1.3254e-05, 'epoch': 0.03}\n",
            "{'loss': 2.0709, 'learning_rate': 1.31976e-05, 'epoch': 0.03}\n",
            "{'loss': 1.9327, 'learning_rate': 1.31412e-05, 'epoch': 0.04}\n",
            "{'loss': 2.1302, 'learning_rate': 1.30848e-05, 'epoch': 0.04}\n",
            "{'loss': 2.1016, 'learning_rate': 1.30284e-05, 'epoch': 0.04}\n",
            "{'loss': 2.4206, 'learning_rate': 1.2972e-05, 'epoch': 0.04}\n",
            "{'loss': 2.0995, 'learning_rate': 1.29156e-05, 'epoch': 0.04}\n",
            "{'loss': 2.0058, 'learning_rate': 1.28592e-05, 'epoch': 0.05}\n",
            "{'loss': 2.136, 'learning_rate': 1.28028e-05, 'epoch': 0.05}\n",
            "{'loss': 1.8072, 'learning_rate': 1.27464e-05, 'epoch': 0.05}\n",
            "{'loss': 2.1964, 'learning_rate': 1.269e-05, 'epoch': 0.05}\n",
            "{'loss': 2.0489, 'learning_rate': 1.26336e-05, 'epoch': 0.05}\n",
            "{'loss': 1.9497, 'learning_rate': 1.25772e-05, 'epoch': 0.06}\n",
            "{'loss': 2.1729, 'learning_rate': 1.25208e-05, 'epoch': 0.06}\n",
            "{'loss': 1.9789, 'learning_rate': 1.24644e-05, 'epoch': 0.06}\n",
            "{'loss': 1.9663, 'learning_rate': 1.2408e-05, 'epoch': 0.06}\n",
            "{'loss': 2.1822, 'learning_rate': 1.23516e-05, 'epoch': 0.06}\n",
            "{'loss': 2.2483, 'learning_rate': 1.22952e-05, 'epoch': 0.07}\n",
            "{'loss': 2.2438, 'learning_rate': 1.22388e-05, 'epoch': 0.07}\n",
            "{'loss': 1.975, 'learning_rate': 1.21824e-05, 'epoch': 0.07}\n",
            "{'loss': 2.1659, 'learning_rate': 1.2126e-05, 'epoch': 0.07}\n",
            "{'loss': 1.9279, 'learning_rate': 1.20696e-05, 'epoch': 0.07}\n",
            "{'loss': 2.1005, 'learning_rate': 1.20132e-05, 'epoch': 0.08}\n",
            "{'loss': 2.13, 'learning_rate': 1.19568e-05, 'epoch': 0.08}\n",
            "{'loss': 1.9257, 'learning_rate': 1.19004e-05, 'epoch': 0.08}\n",
            "{'loss': 2.2051, 'learning_rate': 1.1844e-05, 'epoch': 0.08}\n",
            "{'loss': 2.1809, 'learning_rate': 1.17876e-05, 'epoch': 0.09}\n",
            "{'loss': 2.1643, 'learning_rate': 1.17312e-05, 'epoch': 0.09}\n",
            "{'loss': 2.0804, 'learning_rate': 1.16748e-05, 'epoch': 0.09}\n",
            "{'loss': 2.1068, 'learning_rate': 1.16184e-05, 'epoch': 0.09}\n",
            "{'loss': 1.8966, 'learning_rate': 1.1562e-05, 'epoch': 0.09}\n",
            "{'loss': 2.2392, 'learning_rate': 1.15056e-05, 'epoch': 0.1}\n",
            "{'loss': 2.0965, 'learning_rate': 1.14492e-05, 'epoch': 0.1}\n",
            "{'loss': 2.0291, 'learning_rate': 1.13928e-05, 'epoch': 0.1}\n",
            "{'loss': 2.0722, 'learning_rate': 1.13364e-05, 'epoch': 0.1}\n",
            "{'loss': 2.0735, 'learning_rate': 1.128e-05, 'epoch': 0.1}\n",
            "{'loss': 1.7793, 'learning_rate': 1.12236e-05, 'epoch': 0.11}\n",
            "{'loss': 2.0951, 'learning_rate': 1.11672e-05, 'epoch': 0.11}\n",
            "{'loss': 1.9515, 'learning_rate': 1.11108e-05, 'epoch': 0.11}\n",
            "{'loss': 2.0193, 'learning_rate': 1.10544e-05, 'epoch': 0.11}\n",
            "{'loss': 1.799, 'learning_rate': 1.0998e-05, 'epoch': 0.11}\n",
            "{'loss': 2.0423, 'learning_rate': 1.09416e-05, 'epoch': 0.12}\n",
            "{'loss': 1.7986, 'learning_rate': 1.08852e-05, 'epoch': 0.12}\n",
            "{'loss': 2.1151, 'learning_rate': 1.08288e-05, 'epoch': 0.12}\n",
            "{'loss': 1.8988, 'learning_rate': 1.07724e-05, 'epoch': 0.12}\n",
            "{'loss': 1.8771, 'learning_rate': 1.0716e-05, 'epoch': 0.12}\n",
            "{'loss': 1.8777, 'learning_rate': 1.06596e-05, 'epoch': 0.13}\n",
            "{'loss': 1.833, 'learning_rate': 1.06032e-05, 'epoch': 0.13}\n",
            "{'loss': 1.9709, 'learning_rate': 1.05468e-05, 'epoch': 0.13}\n",
            "{'loss': 1.7922, 'learning_rate': 1.04904e-05, 'epoch': 0.13}\n",
            "{'loss': 1.5351, 'learning_rate': 1.0434e-05, 'epoch': 0.13}\n",
            "{'loss': 1.871, 'learning_rate': 1.03776e-05, 'epoch': 0.14}\n",
            "{'loss': 1.6804, 'learning_rate': 1.03212e-05, 'epoch': 0.14}\n",
            "{'loss': 1.9392, 'learning_rate': 1.02648e-05, 'epoch': 0.14}\n",
            "{'loss': 1.9754, 'learning_rate': 1.02084e-05, 'epoch': 0.14}\n",
            "{'loss': 1.9376, 'learning_rate': 1.0152e-05, 'epoch': 0.15}\n",
            "{'loss': 1.925, 'learning_rate': 1.00956e-05, 'epoch': 0.15}\n",
            "{'loss': 1.9865, 'learning_rate': 1.00392e-05, 'epoch': 0.15}\n",
            "{'loss': 1.8419, 'learning_rate': 9.9828e-06, 'epoch': 0.15}\n",
            "{'loss': 1.8356, 'learning_rate': 9.9264e-06, 'epoch': 0.15}\n",
            "{'loss': 2.1075, 'learning_rate': 9.87e-06, 'epoch': 0.16}\n",
            "{'loss': 1.9372, 'learning_rate': 9.8136e-06, 'epoch': 0.16}\n",
            "{'loss': 2.0885, 'learning_rate': 9.7572e-06, 'epoch': 0.16}\n",
            "{'loss': 1.6107, 'learning_rate': 9.7008e-06, 'epoch': 0.16}\n",
            "{'loss': 2.0541, 'learning_rate': 9.6444e-06, 'epoch': 0.16}\n",
            "{'loss': 2.1277, 'learning_rate': 9.588e-06, 'epoch': 0.17}\n",
            "{'loss': 1.785, 'learning_rate': 9.5316e-06, 'epoch': 0.17}\n",
            "{'loss': 2.2762, 'learning_rate': 9.4752e-06, 'epoch': 0.17}\n",
            "{'loss': 2.0122, 'learning_rate': 9.4188e-06, 'epoch': 0.17}\n",
            "{'loss': 1.8167, 'learning_rate': 9.3624e-06, 'epoch': 0.17}\n",
            "{'loss': 1.7563, 'learning_rate': 9.306e-06, 'epoch': 0.18}\n",
            "{'loss': 2.0605, 'learning_rate': 9.2496e-06, 'epoch': 0.18}\n",
            "{'loss': 1.8955, 'learning_rate': 9.1932e-06, 'epoch': 0.18}\n",
            "{'loss': 1.6919, 'learning_rate': 9.1368e-06, 'epoch': 0.18}\n",
            "{'loss': 1.7764, 'learning_rate': 9.0804e-06, 'epoch': 0.18}\n",
            "{'loss': 2.0141, 'learning_rate': 9.024e-06, 'epoch': 0.19}\n",
            "{'loss': 1.8186, 'learning_rate': 8.9676e-06, 'epoch': 0.19}\n",
            "{'loss': 1.904, 'learning_rate': 8.9112e-06, 'epoch': 0.19}\n",
            "{'loss': 1.887, 'learning_rate': 8.8548e-06, 'epoch': 0.19}\n",
            "{'loss': 1.9642, 'learning_rate': 8.7984e-06, 'epoch': 0.2}\n",
            "{'loss': 2.0206, 'learning_rate': 8.742e-06, 'epoch': 0.2}\n",
            "{'loss': 1.7103, 'learning_rate': 8.6856e-06, 'epoch': 0.2}\n",
            "{'loss': 1.9867, 'learning_rate': 8.6292e-06, 'epoch': 0.2}\n",
            "{'loss': 1.8399, 'learning_rate': 8.5728e-06, 'epoch': 0.2}\n",
            "{'loss': 1.704, 'learning_rate': 8.5164e-06, 'epoch': 0.21}\n",
            "{'loss': 1.9557, 'learning_rate': 8.46e-06, 'epoch': 0.21}\n",
            "{'loss': 1.8636, 'learning_rate': 8.4036e-06, 'epoch': 0.21}\n",
            "{'loss': 1.8413, 'learning_rate': 8.3472e-06, 'epoch': 0.21}\n",
            "{'loss': 1.7768, 'learning_rate': 8.2908e-06, 'epoch': 0.21}\n",
            "{'loss': 1.9569, 'learning_rate': 8.2344e-06, 'epoch': 0.22}\n",
            "{'loss': 1.9165, 'learning_rate': 8.178e-06, 'epoch': 0.22}\n",
            "{'loss': 1.5922, 'learning_rate': 8.1216e-06, 'epoch': 0.22}\n",
            "{'loss': 1.7919, 'learning_rate': 8.0652e-06, 'epoch': 0.22}\n",
            "{'loss': 1.6759, 'learning_rate': 8.0088e-06, 'epoch': 0.22}\n",
            "{'loss': 1.6836, 'learning_rate': 7.9524e-06, 'epoch': 0.23}\n",
            "{'loss': 1.9413, 'learning_rate': 7.896e-06, 'epoch': 0.23}\n",
            "{'loss': 1.7808, 'learning_rate': 7.8396e-06, 'epoch': 0.23}\n",
            "{'loss': 1.8345, 'learning_rate': 7.7832e-06, 'epoch': 0.23}\n",
            "{'loss': 1.8034, 'learning_rate': 7.7268e-06, 'epoch': 0.23}\n",
            "{'loss': 1.8802, 'learning_rate': 7.6704e-06, 'epoch': 0.24}\n",
            "{'loss': 1.8995, 'learning_rate': 7.614000000000001e-06, 'epoch': 0.24}\n",
            "{'loss': 1.7067, 'learning_rate': 7.557600000000001e-06, 'epoch': 0.24}\n",
            "{'loss': 1.8924, 'learning_rate': 7.5012e-06, 'epoch': 0.24}\n",
            "{'loss': 1.8945, 'learning_rate': 7.4448e-06, 'epoch': 0.24}\n",
            "{'loss': 1.5895, 'learning_rate': 7.3884e-06, 'epoch': 0.25}\n",
            "{'loss': 1.5704, 'learning_rate': 7.332e-06, 'epoch': 0.25}\n",
            "{'loss': 1.8226, 'learning_rate': 7.2756e-06, 'epoch': 0.25}\n",
            "{'loss': 1.6539, 'learning_rate': 7.2192e-06, 'epoch': 0.25}\n",
            "{'loss': 1.735, 'learning_rate': 7.1628e-06, 'epoch': 0.26}\n",
            "{'loss': 1.7068, 'learning_rate': 7.1064e-06, 'epoch': 0.26}\n",
            "{'loss': 1.7903, 'learning_rate': 7.05e-06, 'epoch': 0.26}\n",
            "{'loss': 1.8235, 'learning_rate': 6.9936e-06, 'epoch': 0.26}\n",
            "{'loss': 1.4244, 'learning_rate': 6.9372e-06, 'epoch': 0.26}\n",
            "{'loss': 1.9382, 'learning_rate': 6.8808e-06, 'epoch': 0.27}\n",
            "{'loss': 1.7086, 'learning_rate': 6.8244e-06, 'epoch': 0.27}\n",
            "{'loss': 1.7398, 'learning_rate': 6.768e-06, 'epoch': 0.27}\n",
            "{'loss': 1.762, 'learning_rate': 6.7116e-06, 'epoch': 0.27}\n",
            "{'loss': 1.9164, 'learning_rate': 6.6552e-06, 'epoch': 0.27}\n",
            "{'loss': 1.7364, 'learning_rate': 6.5988e-06, 'epoch': 0.28}\n",
            "{'loss': 1.4912, 'learning_rate': 6.5424e-06, 'epoch': 0.28}\n",
            "{'loss': 1.6093, 'learning_rate': 6.486e-06, 'epoch': 0.28}\n",
            "{'loss': 1.8189, 'learning_rate': 6.4296e-06, 'epoch': 0.28}\n",
            "{'loss': 1.8193, 'learning_rate': 6.3732e-06, 'epoch': 0.28}\n",
            "{'loss': 1.8205, 'learning_rate': 6.3168e-06, 'epoch': 0.29}\n",
            "{'loss': 1.6191, 'learning_rate': 6.2604e-06, 'epoch': 0.29}\n",
            "{'loss': 1.5371, 'learning_rate': 6.204e-06, 'epoch': 0.29}\n",
            "{'loss': 1.797, 'learning_rate': 6.1476e-06, 'epoch': 0.29}\n",
            "{'loss': 1.7278, 'learning_rate': 6.0912e-06, 'epoch': 0.29}\n",
            "{'loss': 1.7318, 'learning_rate': 6.0348e-06, 'epoch': 0.3}\n",
            "{'loss': 1.8223, 'learning_rate': 5.9784e-06, 'epoch': 0.3}\n",
            "{'loss': 1.67, 'learning_rate': 5.922e-06, 'epoch': 0.3}\n",
            "{'loss': 1.7475, 'learning_rate': 5.8656e-06, 'epoch': 0.3}\n",
            "{'loss': 1.8086, 'learning_rate': 5.8092e-06, 'epoch': 0.31}\n",
            "{'loss': 1.6914, 'learning_rate': 5.7528e-06, 'epoch': 0.31}\n",
            "{'loss': 1.5596, 'learning_rate': 5.6964e-06, 'epoch': 0.31}\n",
            "{'loss': 1.8479, 'learning_rate': 5.64e-06, 'epoch': 0.31}\n",
            "{'loss': 1.803, 'learning_rate': 5.5836e-06, 'epoch': 0.31}\n",
            "{'loss': 1.857, 'learning_rate': 5.5272e-06, 'epoch': 0.32}\n",
            "{'loss': 1.824, 'learning_rate': 5.4708e-06, 'epoch': 0.32}\n",
            "{'loss': 1.65, 'learning_rate': 5.4144e-06, 'epoch': 0.32}\n",
            "{'loss': 1.9558, 'learning_rate': 5.358e-06, 'epoch': 0.32}\n",
            "{'loss': 1.8571, 'learning_rate': 5.3016e-06, 'epoch': 0.32}\n",
            "{'loss': 1.8799, 'learning_rate': 5.2452e-06, 'epoch': 0.33}\n",
            "{'loss': 1.8893, 'learning_rate': 5.1888e-06, 'epoch': 0.33}\n",
            "{'loss': 1.8179, 'learning_rate': 5.1324e-06, 'epoch': 0.33}\n",
            "{'loss': 1.7152, 'learning_rate': 5.076e-06, 'epoch': 0.33}\n",
            "{'loss': 1.7205, 'learning_rate': 5.0196e-06, 'epoch': 0.33}\n",
            "{'loss': 1.7463, 'learning_rate': 4.9632e-06, 'epoch': 0.34}\n",
            "{'loss': 1.8321, 'learning_rate': 4.9068e-06, 'epoch': 0.34}\n",
            "{'loss': 1.6724, 'learning_rate': 4.8504e-06, 'epoch': 0.34}\n",
            "{'loss': 1.6136, 'learning_rate': 4.794e-06, 'epoch': 0.34}\n",
            "{'loss': 1.6206, 'learning_rate': 4.7376e-06, 'epoch': 0.34}\n",
            "{'loss': 1.3387, 'learning_rate': 4.6812e-06, 'epoch': 0.35}\n",
            "{'loss': 1.9773, 'learning_rate': 4.6248e-06, 'epoch': 0.35}\n",
            "{'loss': 1.7305, 'learning_rate': 4.5684e-06, 'epoch': 0.35}\n",
            "{'loss': 1.7765, 'learning_rate': 4.512e-06, 'epoch': 0.35}\n",
            "{'loss': 1.7242, 'learning_rate': 4.4556e-06, 'epoch': 0.35}\n",
            "{'loss': 1.8376, 'learning_rate': 4.3992e-06, 'epoch': 0.36}\n",
            "{'loss': 1.5408, 'learning_rate': 4.3428e-06, 'epoch': 0.36}\n",
            "{'loss': 1.6811, 'learning_rate': 4.2864e-06, 'epoch': 0.36}\n",
            "{'loss': 1.7935, 'learning_rate': 4.23e-06, 'epoch': 0.36}\n",
            "{'loss': 1.6934, 'learning_rate': 4.1736e-06, 'epoch': 0.37}\n",
            "{'loss': 1.6794, 'learning_rate': 4.1172e-06, 'epoch': 0.37}\n",
            "{'loss': 1.8113, 'learning_rate': 4.0608e-06, 'epoch': 0.37}\n",
            "{'loss': 1.856, 'learning_rate': 4.0044e-06, 'epoch': 0.37}\n",
            "{'loss': 1.8194, 'learning_rate': 3.948e-06, 'epoch': 0.37}\n",
            "{'loss': 1.6794, 'learning_rate': 3.8916e-06, 'epoch': 0.38}\n",
            "{'loss': 1.7214, 'learning_rate': 3.8352e-06, 'epoch': 0.38}\n",
            "{'loss': 1.9652, 'learning_rate': 3.7788000000000006e-06, 'epoch': 0.38}\n",
            "{'loss': 1.675, 'learning_rate': 3.7224e-06, 'epoch': 0.38}\n",
            "{'loss': 1.9322, 'learning_rate': 3.666e-06, 'epoch': 0.38}\n",
            "{'loss': 1.6098, 'learning_rate': 3.6096e-06, 'epoch': 0.39}\n",
            "{'loss': 1.8745, 'learning_rate': 3.5532e-06, 'epoch': 0.39}\n",
            "{'loss': 1.8768, 'learning_rate': 3.4968e-06, 'epoch': 0.39}\n",
            "{'loss': 1.6672, 'learning_rate': 3.4404e-06, 'epoch': 0.39}\n",
            "{'loss': 1.5446, 'learning_rate': 3.384e-06, 'epoch': 0.39}\n",
            "{'loss': 1.902, 'learning_rate': 3.3276e-06, 'epoch': 0.4}\n",
            "{'loss': 1.6388, 'learning_rate': 3.2712e-06, 'epoch': 0.4}\n",
            "{'loss': 1.7947, 'learning_rate': 3.2148e-06, 'epoch': 0.4}\n",
            "{'loss': 1.6788, 'learning_rate': 3.1584e-06, 'epoch': 0.4}\n",
            "{'loss': 1.6624, 'learning_rate': 3.102e-06, 'epoch': 0.4}\n",
            "{'loss': 2.0985, 'learning_rate': 3.0456e-06, 'epoch': 0.41}\n",
            "{'loss': 1.8559, 'learning_rate': 2.9892e-06, 'epoch': 0.41}\n",
            "{'loss': 1.7992, 'learning_rate': 2.9328e-06, 'epoch': 0.41}\n",
            "{'loss': 1.507, 'learning_rate': 2.8764e-06, 'epoch': 0.41}\n",
            "{'loss': 1.5383, 'learning_rate': 2.82e-06, 'epoch': 0.42}\n",
            "{'loss': 1.6859, 'learning_rate': 2.7636e-06, 'epoch': 0.42}\n",
            "{'loss': 1.5468, 'learning_rate': 2.7072e-06, 'epoch': 0.42}\n",
            "{'loss': 1.7214, 'learning_rate': 2.6508e-06, 'epoch': 0.42}\n",
            "{'loss': 1.6452, 'learning_rate': 2.5944e-06, 'epoch': 0.42}\n",
            "{'loss': 1.7527, 'learning_rate': 2.538e-06, 'epoch': 0.43}\n",
            "{'loss': 1.6944, 'learning_rate': 2.4816e-06, 'epoch': 0.43}\n",
            "{'loss': 1.5896, 'learning_rate': 2.4252e-06, 'epoch': 0.43}\n",
            "{'loss': 1.6873, 'learning_rate': 2.3688e-06, 'epoch': 0.43}\n",
            "{'loss': 1.7451, 'learning_rate': 2.3124e-06, 'epoch': 0.43}\n",
            "{'loss': 1.6467, 'learning_rate': 2.256e-06, 'epoch': 0.44}\n",
            "{'loss': 1.7448, 'learning_rate': 2.1996e-06, 'epoch': 0.44}\n",
            "{'loss': 1.518, 'learning_rate': 2.1432e-06, 'epoch': 0.44}\n",
            "{'loss': 1.6873, 'learning_rate': 2.0868e-06, 'epoch': 0.44}\n",
            "{'loss': 1.6325, 'learning_rate': 2.0304e-06, 'epoch': 0.44}\n",
            "{'loss': 1.5717, 'learning_rate': 1.974e-06, 'epoch': 0.45}\n",
            "{'loss': 1.8161, 'learning_rate': 1.9176e-06, 'epoch': 0.45}\n",
            "{'loss': 1.857, 'learning_rate': 1.8612e-06, 'epoch': 0.45}\n",
            "{'loss': 1.713, 'learning_rate': 1.8048e-06, 'epoch': 0.45}\n",
            "{'loss': 1.8816, 'learning_rate': 1.7484e-06, 'epoch': 0.45}\n",
            "{'loss': 1.804, 'learning_rate': 1.692e-06, 'epoch': 0.46}\n",
            "{'loss': 1.7029, 'learning_rate': 1.6356e-06, 'epoch': 0.46}\n",
            "{'loss': 1.9567, 'learning_rate': 1.5792e-06, 'epoch': 0.46}\n",
            "{'loss': 1.8073, 'learning_rate': 1.5228e-06, 'epoch': 0.46}\n",
            "{'loss': 1.7257, 'learning_rate': 1.4664e-06, 'epoch': 0.46}\n",
            "{'loss': 1.7936, 'learning_rate': 1.41e-06, 'epoch': 0.47}\n",
            "{'loss': 1.7653, 'learning_rate': 1.3536e-06, 'epoch': 0.47}\n",
            "{'loss': 1.6649, 'learning_rate': 1.2972e-06, 'epoch': 0.47}\n",
            "{'loss': 1.5604, 'learning_rate': 1.2408e-06, 'epoch': 0.47}\n",
            "{'loss': 1.8212, 'learning_rate': 1.1844e-06, 'epoch': 0.48}\n",
            "{'loss': 1.8081, 'learning_rate': 1.128e-06, 'epoch': 0.48}\n",
            "{'loss': 1.5857, 'learning_rate': 1.0716e-06, 'epoch': 0.48}\n",
            "{'loss': 1.7519, 'learning_rate': 1.0152e-06, 'epoch': 0.48}\n",
            "{'loss': 1.5987, 'learning_rate': 9.588e-07, 'epoch': 0.48}\n",
            "{'loss': 1.6148, 'learning_rate': 9.024e-07, 'epoch': 0.49}\n",
            "{'loss': 1.8468, 'learning_rate': 8.46e-07, 'epoch': 0.49}\n",
            "{'loss': 1.5722, 'learning_rate': 7.896e-07, 'epoch': 0.49}\n",
            "{'loss': 1.552, 'learning_rate': 7.332e-07, 'epoch': 0.49}\n",
            "{'loss': 1.7996, 'learning_rate': 6.768e-07, 'epoch': 0.49}\n",
            "{'loss': 1.6114, 'learning_rate': 6.204e-07, 'epoch': 0.5}\n",
            "{'loss': 1.7335, 'learning_rate': 5.64e-07, 'epoch': 0.5}\n",
            "{'loss': 1.7264, 'learning_rate': 5.076e-07, 'epoch': 0.5}\n",
            "{'loss': 1.4953, 'learning_rate': 4.512e-07, 'epoch': 0.5}\n",
            "{'loss': 1.6358, 'learning_rate': 3.948e-07, 'epoch': 0.5}\n",
            "{'loss': 1.5248, 'learning_rate': 3.384e-07, 'epoch': 0.51}\n",
            "{'loss': 1.753, 'learning_rate': 2.82e-07, 'epoch': 0.51}\n",
            "{'loss': 1.7776, 'learning_rate': 2.256e-07, 'epoch': 0.51}\n",
            "{'loss': 1.6875, 'learning_rate': 1.692e-07, 'epoch': 0.51}\n",
            "{'loss': 1.7404, 'learning_rate': 1.128e-07, 'epoch': 0.51}\n",
            "{'loss': 1.74, 'learning_rate': 5.64e-08, 'epoch': 0.52}\n",
            "{'loss': 1.7975, 'learning_rate': 0.0, 'epoch': 0.52}\n",
            "{'train_runtime': 3469.2728, 'train_samples_per_second': 1.153, 'train_steps_per_second': 0.072, 'train_loss': 1.8476899838447571, 'epoch': 0.52}\n",
            "100% 250/250 [57:46<00:00, 13.87s/it]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▇▆█▅▇▆▇▆▆▃▄▂▃▅▃▄▄▃▂▄▁▁▃▂▃▂▄▃▂▂▃▂▂▃▃▃▂▁▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 0.52\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 1.7975\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 3.5522163658752e+16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.84769\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3469.2728\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 1.153\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.072\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mpious-tree-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/utsa-it-phd/huggingface/runs/d56a5i14\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230729_022406-d56a5i14/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model = AutoModel.from_pretrained(\"curr_model/\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"curr_model/\")\n"
      ],
      "metadata": {
        "id": "O31OaU_Zwhfo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. imports\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer\n",
        "\n",
        "\n",
        "# 1. load a pretrained model\n",
        "model = AutoModelForCausalLMWithValueHead.from_pretrained(\"gpt2\")\n",
        "model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# 2. initialize trainer\n",
        "ppo_config = {\"batch_size\": 1}\n",
        "config = PPOConfig(**ppo_config)\n",
        "ppo_trainer = PPOTrainer(config, model, model_ref, tokenizer)\n",
        "\n",
        "# 3. encode a query\n",
        "query_txt = \"This morning I went to the \"\n",
        "query_tensor = tokenizer.encode(query_txt, return_tensors=\"pt\").to(model.pretrained_model.device)\n",
        "\n",
        "# 4. generate model response\n",
        "generation_kwargs = {\n",
        "    \"min_length\": -1,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id,\n",
        "    \"max_new_tokens\": 20,\n",
        "}\n",
        "response_tensor = ppo_trainer.generate([item for item in query_tensor], return_prompt=False, **generation_kwargs)\n",
        "response_txt = tokenizer.decode(response_tensor[0])\n",
        "\n",
        "# 5. define a reward for response\n",
        "# (this could be any reward such as human feedback or output from another model)\n",
        "reward = [torch.tensor(1.0, device=model.pretrained_model.device)]\n",
        "\n",
        "# 6. train model with ppo\n",
        "train_stats = ppo_trainer.step([query_tensor[0]], [response_tensor[0]], reward)"
      ],
      "metadata": {
        "id": "3PGCA4zSdhid",
        "outputId": "4f9c704b-a026-4603-e9d1-9a784c641004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aXDjAycD-AYv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}