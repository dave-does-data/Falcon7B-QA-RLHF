{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dave-does-data/llm-qa-rlhf/blob/main/llm_qa_plhf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "62mgWR1fQ94z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/dave-does-data/llm-qa-rlhf.git\n",
        "!pip install -r llm-qa-rlhf/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgo594cZnoTr",
        "outputId": "019f0eba-85da-4066-a1a3-61877cf9c3be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "I-7TCRQpVaJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3401409-3ab7-486d-e55f-7865b9de68d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdave-does-data\u001b[0m (\u001b[33mutsa-it-phd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llm-qa-rlhf/src/trl/sft_trainer.py \\\n",
        "    --model_name meta-llama/Llama-2-7b-hf \\\n",
        "    --dataset_name dave-does-data/databricks-dolly-qa-subset-7k \\\n",
        "    --log_with 'wandb' \\\n",
        "    --logging_steps 1 \\\n",
        "    --load_in_8bit \\\n",
        "    --use_peft \\\n",
        "    --batch_size 4 \\\n",
        "    --gradient_accumulation_steps 4 \\\n",
        "    --max_steps 500"
      ],
      "metadata": {
        "id": "M86KHvVXgxzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a2a4e3-0e79-44f8-f67d-f895dafa757d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-25 21:36:05.954671: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100% 2/2 [01:07<00:00, 33.72s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "Using pad_token, but it is not set yet.\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdave-does-data\u001b[0m (\u001b[33mutsa-it-phd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.7 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230725_213729-i0vt2qoe\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mresilient-spaceship-7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/utsa-it-phd/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/utsa-it-phd/huggingface/runs/i0vt2qoe\u001b[0m\n",
            "  0% 0/500 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 2.1927, 'learning_rate': 1.40718e-05, 'epoch': 0.0}\n",
            "{'loss': 2.3581, 'learning_rate': 1.40436e-05, 'epoch': 0.0}\n",
            "{'loss': 2.3389, 'learning_rate': 1.40154e-05, 'epoch': 0.01}\n",
            "{'loss': 2.3071, 'learning_rate': 1.39872e-05, 'epoch': 0.01}\n",
            "{'loss': 2.1381, 'learning_rate': 1.3959e-05, 'epoch': 0.01}\n",
            "{'loss': 2.2466, 'learning_rate': 1.39308e-05, 'epoch': 0.01}\n",
            "{'loss': 2.0931, 'learning_rate': 1.39026e-05, 'epoch': 0.01}\n",
            "{'loss': 2.3145, 'learning_rate': 1.38744e-05, 'epoch': 0.02}\n",
            "{'loss': 2.061, 'learning_rate': 1.38462e-05, 'epoch': 0.02}\n",
            "{'loss': 1.947, 'learning_rate': 1.3818e-05, 'epoch': 0.02}\n",
            "{'loss': 2.153, 'learning_rate': 1.37898e-05, 'epoch': 0.02}\n",
            "{'loss': 2.3057, 'learning_rate': 1.37616e-05, 'epoch': 0.02}\n",
            "{'loss': 2.4049, 'learning_rate': 1.37334e-05, 'epoch': 0.03}\n",
            "{'loss': 2.1256, 'learning_rate': 1.37052e-05, 'epoch': 0.03}\n",
            "{'loss': 2.088, 'learning_rate': 1.3677e-05, 'epoch': 0.03}\n",
            "{'loss': 2.0693, 'learning_rate': 1.36488e-05, 'epoch': 0.03}\n",
            "{'loss': 1.9313, 'learning_rate': 1.36206e-05, 'epoch': 0.04}\n",
            "{'loss': 2.1287, 'learning_rate': 1.35924e-05, 'epoch': 0.04}\n",
            "{'loss': 2.0992, 'learning_rate': 1.35642e-05, 'epoch': 0.04}\n",
            "{'loss': 2.418, 'learning_rate': 1.3536e-05, 'epoch': 0.04}\n",
            "{'loss': 2.0977, 'learning_rate': 1.35078e-05, 'epoch': 0.04}\n",
            "{'loss': 2.0034, 'learning_rate': 1.34796e-05, 'epoch': 0.05}\n",
            "{'loss': 2.134, 'learning_rate': 1.34514e-05, 'epoch': 0.05}\n",
            "{'loss': 1.8047, 'learning_rate': 1.34232e-05, 'epoch': 0.05}\n",
            "{'loss': 2.1931, 'learning_rate': 1.3395e-05, 'epoch': 0.05}\n",
            "{'loss': 2.0451, 'learning_rate': 1.33668e-05, 'epoch': 0.05}\n",
            "{'loss': 1.9467, 'learning_rate': 1.33386e-05, 'epoch': 0.06}\n",
            "{'loss': 2.17, 'learning_rate': 1.33104e-05, 'epoch': 0.06}\n",
            "{'loss': 1.9761, 'learning_rate': 1.32822e-05, 'epoch': 0.06}\n",
            "{'loss': 1.9628, 'learning_rate': 1.3254e-05, 'epoch': 0.06}\n",
            "{'loss': 2.1771, 'learning_rate': 1.32258e-05, 'epoch': 0.06}\n",
            "{'loss': 2.2427, 'learning_rate': 1.31976e-05, 'epoch': 0.07}\n",
            "{'loss': 2.2397, 'learning_rate': 1.3169400000000001e-05, 'epoch': 0.07}\n",
            "{'loss': 1.9702, 'learning_rate': 1.31412e-05, 'epoch': 0.07}\n",
            "{'loss': 2.1605, 'learning_rate': 1.3113000000000001e-05, 'epoch': 0.07}\n",
            "{'loss': 1.9234, 'learning_rate': 1.30848e-05, 'epoch': 0.07}\n",
            "{'loss': 2.093, 'learning_rate': 1.3056600000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 2.1236, 'learning_rate': 1.30284e-05, 'epoch': 0.08}\n",
            "{'loss': 1.9206, 'learning_rate': 1.3000200000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 2.1993, 'learning_rate': 1.2972e-05, 'epoch': 0.08}\n",
            "{'loss': 2.1734, 'learning_rate': 1.2943800000000001e-05, 'epoch': 0.09}\n",
            "{'loss': 2.1594, 'learning_rate': 1.29156e-05, 'epoch': 0.09}\n",
            "{'loss': 2.074, 'learning_rate': 1.2887400000000001e-05, 'epoch': 0.09}\n",
            "{'loss': 2.0968, 'learning_rate': 1.28592e-05, 'epoch': 0.09}\n",
            "{'loss': 1.8894, 'learning_rate': 1.2831000000000001e-05, 'epoch': 0.09}\n",
            "{'loss': 2.2317, 'learning_rate': 1.28028e-05, 'epoch': 0.1}\n",
            "{'loss': 2.0861, 'learning_rate': 1.2774600000000001e-05, 'epoch': 0.1}\n",
            "{'loss': 2.0227, 'learning_rate': 1.27464e-05, 'epoch': 0.1}\n",
            "{'loss': 2.0636, 'learning_rate': 1.2718200000000001e-05, 'epoch': 0.1}\n",
            "{'loss': 2.0649, 'learning_rate': 1.269e-05, 'epoch': 0.1}\n",
            "{'loss': 1.7688, 'learning_rate': 1.2661800000000001e-05, 'epoch': 0.11}\n",
            "{'loss': 2.0839, 'learning_rate': 1.26336e-05, 'epoch': 0.11}\n",
            "{'loss': 1.9375, 'learning_rate': 1.2605400000000001e-05, 'epoch': 0.11}\n",
            "{'loss': 2.0, 'learning_rate': 1.25772e-05, 'epoch': 0.11}\n",
            "{'loss': 1.788, 'learning_rate': 1.2549000000000001e-05, 'epoch': 0.11}\n",
            "{'loss': 2.0298, 'learning_rate': 1.25208e-05, 'epoch': 0.12}\n",
            "{'loss': 1.7865, 'learning_rate': 1.2492600000000001e-05, 'epoch': 0.12}\n",
            "{'loss': 2.1009, 'learning_rate': 1.24644e-05, 'epoch': 0.12}\n",
            "{'loss': 1.8894, 'learning_rate': 1.2436200000000001e-05, 'epoch': 0.12}\n",
            "{'loss': 1.8624, 'learning_rate': 1.2408e-05, 'epoch': 0.12}\n",
            "{'loss': 1.8667, 'learning_rate': 1.2379800000000001e-05, 'epoch': 0.13}\n",
            "{'loss': 1.8168, 'learning_rate': 1.23516e-05, 'epoch': 0.13}\n",
            "{'loss': 1.9557, 'learning_rate': 1.23234e-05, 'epoch': 0.13}\n",
            "{'loss': 1.7779, 'learning_rate': 1.22952e-05, 'epoch': 0.13}\n",
            "{'loss': 1.522, 'learning_rate': 1.2267e-05, 'epoch': 0.13}\n",
            "{'loss': 1.851, 'learning_rate': 1.22388e-05, 'epoch': 0.14}\n",
            "{'loss': 1.6641, 'learning_rate': 1.22106e-05, 'epoch': 0.14}\n",
            "{'loss': 1.9187, 'learning_rate': 1.21824e-05, 'epoch': 0.14}\n",
            "{'loss': 1.9554, 'learning_rate': 1.21542e-05, 'epoch': 0.14}\n",
            "{'loss': 1.9205, 'learning_rate': 1.2126e-05, 'epoch': 0.15}\n",
            "{'loss': 1.895, 'learning_rate': 1.20978e-05, 'epoch': 0.15}\n",
            "{'loss': 1.9625, 'learning_rate': 1.20696e-05, 'epoch': 0.15}\n",
            "{'loss': 1.8152, 'learning_rate': 1.20414e-05, 'epoch': 0.15}\n",
            "{'loss': 1.8153, 'learning_rate': 1.20132e-05, 'epoch': 0.15}\n",
            "{'loss': 2.0735, 'learning_rate': 1.1985e-05, 'epoch': 0.16}\n",
            "{'loss': 1.9119, 'learning_rate': 1.19568e-05, 'epoch': 0.16}\n",
            "{'loss': 2.0671, 'learning_rate': 1.19286e-05, 'epoch': 0.16}\n",
            "{'loss': 1.5897, 'learning_rate': 1.19004e-05, 'epoch': 0.16}\n",
            "{'loss': 2.0257, 'learning_rate': 1.18722e-05, 'epoch': 0.16}\n",
            "{'loss': 2.0918, 'learning_rate': 1.1844e-05, 'epoch': 0.17}\n",
            "{'loss': 1.7585, 'learning_rate': 1.18158e-05, 'epoch': 0.17}\n",
            "{'loss': 2.2359, 'learning_rate': 1.17876e-05, 'epoch': 0.17}\n",
            "{'loss': 1.99, 'learning_rate': 1.17594e-05, 'epoch': 0.17}\n",
            "{'loss': 1.7719, 'learning_rate': 1.17312e-05, 'epoch': 0.17}\n",
            "{'loss': 1.7092, 'learning_rate': 1.1703e-05, 'epoch': 0.18}\n",
            "{'loss': 2.021, 'learning_rate': 1.16748e-05, 'epoch': 0.18}\n",
            "{'loss': 1.8751, 'learning_rate': 1.16466e-05, 'epoch': 0.18}\n",
            "{'loss': 1.6631, 'learning_rate': 1.16184e-05, 'epoch': 0.18}\n",
            "{'loss': 1.7492, 'learning_rate': 1.15902e-05, 'epoch': 0.18}\n",
            "{'loss': 1.971, 'learning_rate': 1.1562e-05, 'epoch': 0.19}\n",
            "{'loss': 1.7692, 'learning_rate': 1.15338e-05, 'epoch': 0.19}\n",
            "{'loss': 1.8723, 'learning_rate': 1.15056e-05, 'epoch': 0.19}\n",
            "{'loss': 1.8358, 'learning_rate': 1.14774e-05, 'epoch': 0.19}\n",
            "{'loss': 1.925, 'learning_rate': 1.14492e-05, 'epoch': 0.2}\n",
            "{'loss': 1.984, 'learning_rate': 1.1421000000000001e-05, 'epoch': 0.2}\n",
            "{'loss': 1.6733, 'learning_rate': 1.13928e-05, 'epoch': 0.2}\n",
            "{'loss': 1.9392, 'learning_rate': 1.1364600000000001e-05, 'epoch': 0.2}\n",
            "{'loss': 1.7881, 'learning_rate': 1.13364e-05, 'epoch': 0.2}\n",
            "{'loss': 1.66, 'learning_rate': 1.1308200000000001e-05, 'epoch': 0.21}\n",
            "{'loss': 1.899, 'learning_rate': 1.128e-05, 'epoch': 0.21}\n",
            "{'loss': 1.8029, 'learning_rate': 1.1251800000000001e-05, 'epoch': 0.21}\n",
            "{'loss': 1.7854, 'learning_rate': 1.12236e-05, 'epoch': 0.21}\n",
            "{'loss': 1.7265, 'learning_rate': 1.1195400000000001e-05, 'epoch': 0.21}\n",
            "{'loss': 1.9114, 'learning_rate': 1.11672e-05, 'epoch': 0.22}\n",
            "{'loss': 1.8645, 'learning_rate': 1.1139000000000001e-05, 'epoch': 0.22}\n",
            "{'loss': 1.5496, 'learning_rate': 1.11108e-05, 'epoch': 0.22}\n",
            "{'loss': 1.763, 'learning_rate': 1.1082600000000001e-05, 'epoch': 0.22}\n",
            "{'loss': 1.6222, 'learning_rate': 1.10544e-05, 'epoch': 0.22}\n",
            "{'loss': 1.6482, 'learning_rate': 1.1026200000000001e-05, 'epoch': 0.23}\n",
            "{'loss': 1.9014, 'learning_rate': 1.0998e-05, 'epoch': 0.23}\n",
            "{'loss': 1.7322, 'learning_rate': 1.0969800000000001e-05, 'epoch': 0.23}\n",
            "{'loss': 1.7957, 'learning_rate': 1.09416e-05, 'epoch': 0.23}\n",
            "{'loss': 1.7535, 'learning_rate': 1.0913400000000001e-05, 'epoch': 0.23}\n",
            "{'loss': 1.8156, 'learning_rate': 1.08852e-05, 'epoch': 0.24}\n",
            "{'loss': 1.8575, 'learning_rate': 1.0857000000000001e-05, 'epoch': 0.24}\n",
            "{'loss': 1.6642, 'learning_rate': 1.08288e-05, 'epoch': 0.24}\n",
            "{'loss': 1.8609, 'learning_rate': 1.0800600000000001e-05, 'epoch': 0.24}\n",
            "{'loss': 1.8473, 'learning_rate': 1.07724e-05, 'epoch': 0.24}\n",
            "{'loss': 1.5556, 'learning_rate': 1.0744200000000001e-05, 'epoch': 0.25}\n",
            "{'loss': 1.5408, 'learning_rate': 1.0716e-05, 'epoch': 0.25}\n",
            "{'loss': 1.7784, 'learning_rate': 1.0687800000000001e-05, 'epoch': 0.25}\n",
            "{'loss': 1.6216, 'learning_rate': 1.06596e-05, 'epoch': 0.25}\n",
            "{'loss': 1.7145, 'learning_rate': 1.0631400000000001e-05, 'epoch': 0.26}\n",
            "{'loss': 1.6534, 'learning_rate': 1.06032e-05, 'epoch': 0.26}\n",
            "{'loss': 1.7507, 'learning_rate': 1.0575e-05, 'epoch': 0.26}\n",
            "{'loss': 1.7884, 'learning_rate': 1.05468e-05, 'epoch': 0.26}\n",
            "{'loss': 1.3817, 'learning_rate': 1.05186e-05, 'epoch': 0.26}\n",
            "{'loss': 1.8991, 'learning_rate': 1.04904e-05, 'epoch': 0.27}\n",
            "{'loss': 1.6779, 'learning_rate': 1.04622e-05, 'epoch': 0.27}\n",
            "{'loss': 1.7019, 'learning_rate': 1.0434e-05, 'epoch': 0.27}\n",
            "{'loss': 1.7358, 'learning_rate': 1.04058e-05, 'epoch': 0.27}\n",
            "{'loss': 1.8876, 'learning_rate': 1.03776e-05, 'epoch': 0.27}\n",
            "{'loss': 1.6955, 'learning_rate': 1.03494e-05, 'epoch': 0.28}\n",
            "{'loss': 1.4581, 'learning_rate': 1.03212e-05, 'epoch': 0.28}\n",
            "{'loss': 1.5599, 'learning_rate': 1.0293e-05, 'epoch': 0.28}\n",
            "{'loss': 1.7826, 'learning_rate': 1.02648e-05, 'epoch': 0.28}\n",
            "{'loss': 1.7791, 'learning_rate': 1.02366e-05, 'epoch': 0.28}\n",
            "{'loss': 1.7821, 'learning_rate': 1.02084e-05, 'epoch': 0.29}\n",
            "{'loss': 1.595, 'learning_rate': 1.01802e-05, 'epoch': 0.29}\n",
            "{'loss': 1.4961, 'learning_rate': 1.0152e-05, 'epoch': 0.29}\n",
            "{'loss': 1.7712, 'learning_rate': 1.01238e-05, 'epoch': 0.29}\n",
            "{'loss': 1.6894, 'learning_rate': 1.00956e-05, 'epoch': 0.29}\n",
            "{'loss': 1.6976, 'learning_rate': 1.00674e-05, 'epoch': 0.3}\n",
            "{'loss': 1.7727, 'learning_rate': 1.00392e-05, 'epoch': 0.3}\n",
            "{'loss': 1.6432, 'learning_rate': 1.0011e-05, 'epoch': 0.3}\n",
            "{'loss': 1.7058, 'learning_rate': 9.9828e-06, 'epoch': 0.3}\n",
            "{'loss': 1.7615, 'learning_rate': 9.9546e-06, 'epoch': 0.31}\n",
            "{'loss': 1.6386, 'learning_rate': 9.9264e-06, 'epoch': 0.31}\n",
            "{'loss': 1.5229, 'learning_rate': 9.8982e-06, 'epoch': 0.31}\n",
            "{'loss': 1.8237, 'learning_rate': 9.87e-06, 'epoch': 0.31}\n",
            "{'loss': 1.7566, 'learning_rate': 9.8418e-06, 'epoch': 0.31}\n",
            "{'loss': 1.8201, 'learning_rate': 9.8136e-06, 'epoch': 0.32}\n",
            "{'loss': 1.7975, 'learning_rate': 9.7854e-06, 'epoch': 0.32}\n",
            "{'loss': 1.6079, 'learning_rate': 9.7572e-06, 'epoch': 0.32}\n",
            "{'loss': 1.9185, 'learning_rate': 9.729e-06, 'epoch': 0.32}\n",
            "{'loss': 1.8178, 'learning_rate': 9.7008e-06, 'epoch': 0.32}\n",
            "{'loss': 1.8604, 'learning_rate': 9.672600000000001e-06, 'epoch': 0.33}\n",
            "{'loss': 1.8374, 'learning_rate': 9.6444e-06, 'epoch': 0.33}\n",
            "{'loss': 1.779, 'learning_rate': 9.616200000000001e-06, 'epoch': 0.33}\n",
            "{'loss': 1.6728, 'learning_rate': 9.588e-06, 'epoch': 0.33}\n",
            "{'loss': 1.6769, 'learning_rate': 9.559800000000001e-06, 'epoch': 0.33}\n",
            "{'loss': 1.6826, 'learning_rate': 9.5316e-06, 'epoch': 0.34}\n",
            "{'loss': 1.7619, 'learning_rate': 9.503400000000001e-06, 'epoch': 0.34}\n",
            "{'loss': 1.6324, 'learning_rate': 9.4752e-06, 'epoch': 0.34}\n",
            "{'loss': 1.5481, 'learning_rate': 9.447000000000001e-06, 'epoch': 0.34}\n",
            "{'loss': 1.5817, 'learning_rate': 9.4188e-06, 'epoch': 0.34}\n",
            "{'loss': 1.3021, 'learning_rate': 9.390600000000001e-06, 'epoch': 0.35}\n",
            "{'loss': 1.9315, 'learning_rate': 9.3624e-06, 'epoch': 0.35}\n",
            "{'loss': 1.6942, 'learning_rate': 9.334200000000001e-06, 'epoch': 0.35}\n",
            "{'loss': 1.7481, 'learning_rate': 9.306e-06, 'epoch': 0.35}\n",
            "{'loss': 1.6797, 'learning_rate': 9.277800000000001e-06, 'epoch': 0.35}\n",
            "{'loss': 1.8102, 'learning_rate': 9.2496e-06, 'epoch': 0.36}\n",
            "{'loss': 1.5014, 'learning_rate': 9.221400000000001e-06, 'epoch': 0.36}\n",
            "{'loss': 1.6471, 'learning_rate': 9.1932e-06, 'epoch': 0.36}\n",
            "{'loss': 1.7476, 'learning_rate': 9.165000000000001e-06, 'epoch': 0.36}\n",
            "{'loss': 1.6571, 'learning_rate': 9.1368e-06, 'epoch': 0.37}\n",
            "{'loss': 1.6591, 'learning_rate': 9.108600000000001e-06, 'epoch': 0.37}\n",
            "{'loss': 1.7879, 'learning_rate': 9.0804e-06, 'epoch': 0.37}\n",
            "{'loss': 1.805, 'learning_rate': 9.052200000000001e-06, 'epoch': 0.37}\n",
            "{'loss': 1.7748, 'learning_rate': 9.024e-06, 'epoch': 0.37}\n",
            "{'loss': 1.6401, 'learning_rate': 8.995800000000001e-06, 'epoch': 0.38}\n",
            "{'loss': 1.6851, 'learning_rate': 8.9676e-06, 'epoch': 0.38}\n",
            "{'loss': 1.9217, 'learning_rate': 8.939400000000001e-06, 'epoch': 0.38}\n",
            "{'loss': 1.6285, 'learning_rate': 8.9112e-06, 'epoch': 0.38}\n",
            "{'loss': 1.8898, 'learning_rate': 8.883000000000001e-06, 'epoch': 0.38}\n",
            "{'loss': 1.5686, 'learning_rate': 8.8548e-06, 'epoch': 0.39}\n",
            "{'loss': 1.8433, 'learning_rate': 8.826600000000001e-06, 'epoch': 0.39}\n",
            "{'loss': 1.8467, 'learning_rate': 8.7984e-06, 'epoch': 0.39}\n",
            "{'loss': 1.6273, 'learning_rate': 8.7702e-06, 'epoch': 0.39}\n",
            "{'loss': 1.5119, 'learning_rate': 8.742e-06, 'epoch': 0.39}\n",
            "{'loss': 1.8663, 'learning_rate': 8.7138e-06, 'epoch': 0.4}\n",
            "{'loss': 1.5843, 'learning_rate': 8.6856e-06, 'epoch': 0.4}\n",
            "{'loss': 1.7416, 'learning_rate': 8.6574e-06, 'epoch': 0.4}\n",
            "{'loss': 1.6438, 'learning_rate': 8.6292e-06, 'epoch': 0.4}\n",
            "{'loss': 1.6064, 'learning_rate': 8.601e-06, 'epoch': 0.4}\n",
            "{'loss': 2.0649, 'learning_rate': 8.5728e-06, 'epoch': 0.41}\n",
            "{'loss': 1.8032, 'learning_rate': 8.5446e-06, 'epoch': 0.41}\n",
            "{'loss': 1.7668, 'learning_rate': 8.5164e-06, 'epoch': 0.41}\n",
            "{'loss': 1.4858, 'learning_rate': 8.4882e-06, 'epoch': 0.41}\n",
            "{'loss': 1.5073, 'learning_rate': 8.46e-06, 'epoch': 0.42}\n",
            "{'loss': 1.6448, 'learning_rate': 8.4318e-06, 'epoch': 0.42}\n",
            "{'loss': 1.5016, 'learning_rate': 8.4036e-06, 'epoch': 0.42}\n",
            "{'loss': 1.6928, 'learning_rate': 8.3754e-06, 'epoch': 0.42}\n",
            "{'loss': 1.61, 'learning_rate': 8.3472e-06, 'epoch': 0.42}\n",
            "{'loss': 1.7203, 'learning_rate': 8.319e-06, 'epoch': 0.43}\n",
            "{'loss': 1.6421, 'learning_rate': 8.2908e-06, 'epoch': 0.43}\n",
            "{'loss': 1.5662, 'learning_rate': 8.2626e-06, 'epoch': 0.43}\n",
            "{'loss': 1.6482, 'learning_rate': 8.2344e-06, 'epoch': 0.43}\n",
            "{'loss': 1.7254, 'learning_rate': 8.2062e-06, 'epoch': 0.43}\n",
            "{'loss': 1.6339, 'learning_rate': 8.178e-06, 'epoch': 0.44}\n",
            "{'loss': 1.7039, 'learning_rate': 8.1498e-06, 'epoch': 0.44}\n",
            "{'loss': 1.4757, 'learning_rate': 8.1216e-06, 'epoch': 0.44}\n",
            "{'loss': 1.6646, 'learning_rate': 8.0934e-06, 'epoch': 0.44}\n",
            "{'loss': 1.6, 'learning_rate': 8.0652e-06, 'epoch': 0.44}\n",
            "{'loss': 1.5347, 'learning_rate': 8.037e-06, 'epoch': 0.45}\n",
            "{'loss': 1.7778, 'learning_rate': 8.0088e-06, 'epoch': 0.45}\n",
            "{'loss': 1.7988, 'learning_rate': 7.9806e-06, 'epoch': 0.45}\n",
            "{'loss': 1.6991, 'learning_rate': 7.9524e-06, 'epoch': 0.45}\n",
            "{'loss': 1.818, 'learning_rate': 7.924200000000001e-06, 'epoch': 0.45}\n",
            "{'loss': 1.7444, 'learning_rate': 7.896e-06, 'epoch': 0.46}\n",
            "{'loss': 1.6791, 'learning_rate': 7.867800000000001e-06, 'epoch': 0.46}\n",
            "{'loss': 1.9159, 'learning_rate': 7.8396e-06, 'epoch': 0.46}\n",
            "{'loss': 1.7735, 'learning_rate': 7.811400000000001e-06, 'epoch': 0.46}\n",
            "{'loss': 1.6819, 'learning_rate': 7.7832e-06, 'epoch': 0.46}\n",
            "{'loss': 1.7504, 'learning_rate': 7.755000000000001e-06, 'epoch': 0.47}\n",
            "{'loss': 1.7417, 'learning_rate': 7.7268e-06, 'epoch': 0.47}\n",
            "{'loss': 1.6216, 'learning_rate': 7.698600000000001e-06, 'epoch': 0.47}\n",
            "{'loss': 1.5387, 'learning_rate': 7.6704e-06, 'epoch': 0.47}\n",
            "{'loss': 1.7651, 'learning_rate': 7.642200000000001e-06, 'epoch': 0.48}\n",
            "{'loss': 1.7652, 'learning_rate': 7.614000000000001e-06, 'epoch': 0.48}\n",
            "{'loss': 1.5264, 'learning_rate': 7.585800000000001e-06, 'epoch': 0.48}\n",
            "{'loss': 1.711, 'learning_rate': 7.557600000000001e-06, 'epoch': 0.48}\n",
            "{'loss': 1.5627, 'learning_rate': 7.529400000000001e-06, 'epoch': 0.48}\n",
            "{'loss': 1.5652, 'learning_rate': 7.5012e-06, 'epoch': 0.49}\n",
            "{'loss': 1.7929, 'learning_rate': 7.473e-06, 'epoch': 0.49}\n",
            "{'loss': 1.5158, 'learning_rate': 7.4448e-06, 'epoch': 0.49}\n",
            "{'loss': 1.4896, 'learning_rate': 7.4166e-06, 'epoch': 0.49}\n",
            "{'loss': 1.7758, 'learning_rate': 7.3884e-06, 'epoch': 0.49}\n",
            "{'loss': 1.5687, 'learning_rate': 7.3602e-06, 'epoch': 0.5}\n",
            "{'loss': 1.6989, 'learning_rate': 7.332e-06, 'epoch': 0.5}\n",
            "{'loss': 1.6866, 'learning_rate': 7.3038e-06, 'epoch': 0.5}\n",
            "{'loss': 1.4587, 'learning_rate': 7.2756e-06, 'epoch': 0.5}\n",
            "{'loss': 1.5971, 'learning_rate': 7.2474e-06, 'epoch': 0.5}\n",
            "{'loss': 1.5055, 'learning_rate': 7.2192e-06, 'epoch': 0.51}\n",
            "{'loss': 1.7227, 'learning_rate': 7.191e-06, 'epoch': 0.51}\n",
            "{'loss': 1.7208, 'learning_rate': 7.1628e-06, 'epoch': 0.51}\n",
            "{'loss': 1.6307, 'learning_rate': 7.1346e-06, 'epoch': 0.51}\n",
            "{'loss': 1.6915, 'learning_rate': 7.1064e-06, 'epoch': 0.51}\n",
            "{'loss': 1.7064, 'learning_rate': 7.0782e-06, 'epoch': 0.52}\n",
            "{'loss': 1.7455, 'learning_rate': 7.05e-06, 'epoch': 0.52}\n",
            "{'loss': 1.5116, 'learning_rate': 7.0218e-06, 'epoch': 0.52}\n",
            "{'loss': 1.6396, 'learning_rate': 6.9936e-06, 'epoch': 0.52}\n",
            "{'loss': 1.566, 'learning_rate': 6.9654e-06, 'epoch': 0.53}\n",
            "{'loss': 1.5937, 'learning_rate': 6.9372e-06, 'epoch': 0.53}\n",
            "{'loss': 1.5286, 'learning_rate': 6.909e-06, 'epoch': 0.53}\n",
            "{'loss': 1.7301, 'learning_rate': 6.8808e-06, 'epoch': 0.53}\n",
            "{'loss': 1.771, 'learning_rate': 6.8526e-06, 'epoch': 0.53}\n",
            "{'loss': 1.8053, 'learning_rate': 6.8244e-06, 'epoch': 0.54}\n",
            "{'loss': 1.5924, 'learning_rate': 6.7962e-06, 'epoch': 0.54}\n",
            "{'loss': 1.6171, 'learning_rate': 6.768e-06, 'epoch': 0.54}\n",
            "{'loss': 1.7646, 'learning_rate': 6.7398e-06, 'epoch': 0.54}\n",
            "{'loss': 1.5096, 'learning_rate': 6.7116e-06, 'epoch': 0.54}\n",
            "{'loss': 1.8235, 'learning_rate': 6.6834e-06, 'epoch': 0.55}\n",
            "{'loss': 1.7784, 'learning_rate': 6.6552e-06, 'epoch': 0.55}\n",
            "{'loss': 1.8174, 'learning_rate': 6.627e-06, 'epoch': 0.55}\n",
            "{'loss': 1.8597, 'learning_rate': 6.5988e-06, 'epoch': 0.55}\n",
            "{'loss': 1.8121, 'learning_rate': 6.5706e-06, 'epoch': 0.55}\n",
            "{'loss': 1.8034, 'learning_rate': 6.5424e-06, 'epoch': 0.56}\n",
            "{'loss': 1.7174, 'learning_rate': 6.5142e-06, 'epoch': 0.56}\n",
            "{'loss': 1.6495, 'learning_rate': 6.486e-06, 'epoch': 0.56}\n",
            "{'loss': 1.7005, 'learning_rate': 6.4578e-06, 'epoch': 0.56}\n",
            "{'loss': 1.7026, 'learning_rate': 6.4296e-06, 'epoch': 0.56}\n",
            "{'loss': 1.6529, 'learning_rate': 6.4014e-06, 'epoch': 0.57}\n",
            "{'loss': 1.5876, 'learning_rate': 6.3732e-06, 'epoch': 0.57}\n",
            "{'loss': 1.625, 'learning_rate': 6.345e-06, 'epoch': 0.57}\n",
            "{'loss': 1.7798, 'learning_rate': 6.3168e-06, 'epoch': 0.57}\n",
            "{'loss': 1.8275, 'learning_rate': 6.2886e-06, 'epoch': 0.57}\n",
            "{'loss': 1.8004, 'learning_rate': 6.2604e-06, 'epoch': 0.58}\n",
            "{'loss': 1.8253, 'learning_rate': 6.2322e-06, 'epoch': 0.58}\n",
            "{'loss': 1.4835, 'learning_rate': 6.204e-06, 'epoch': 0.58}\n",
            "{'loss': 1.7068, 'learning_rate': 6.1758e-06, 'epoch': 0.58}\n",
            "{'loss': 1.6451, 'learning_rate': 6.1476e-06, 'epoch': 0.59}\n",
            "{'loss': 1.7573, 'learning_rate': 6.1194e-06, 'epoch': 0.59}\n",
            "{'loss': 1.6713, 'learning_rate': 6.0912e-06, 'epoch': 0.59}\n",
            "{'loss': 1.6402, 'learning_rate': 6.063e-06, 'epoch': 0.59}\n",
            "{'loss': 1.6186, 'learning_rate': 6.0348e-06, 'epoch': 0.59}\n",
            "{'loss': 1.6038, 'learning_rate': 6.0066e-06, 'epoch': 0.6}\n",
            "{'loss': 1.7225, 'learning_rate': 5.9784e-06, 'epoch': 0.6}\n",
            "{'loss': 1.851, 'learning_rate': 5.9502e-06, 'epoch': 0.6}\n",
            "{'loss': 1.5553, 'learning_rate': 5.922e-06, 'epoch': 0.6}\n",
            "{'loss': 1.4579, 'learning_rate': 5.8938e-06, 'epoch': 0.6}\n",
            "{'loss': 1.4459, 'learning_rate': 5.8656e-06, 'epoch': 0.61}\n",
            "{'loss': 1.7508, 'learning_rate': 5.8374e-06, 'epoch': 0.61}\n",
            "{'loss': 1.5829, 'learning_rate': 5.8092e-06, 'epoch': 0.61}\n",
            "{'loss': 1.2385, 'learning_rate': 5.781e-06, 'epoch': 0.61}\n",
            "{'loss': 1.5563, 'learning_rate': 5.7528e-06, 'epoch': 0.61}\n",
            "{'loss': 1.6937, 'learning_rate': 5.7246e-06, 'epoch': 0.62}\n",
            "{'loss': 1.736, 'learning_rate': 5.6964e-06, 'epoch': 0.62}\n",
            "{'loss': 1.7657, 'learning_rate': 5.6682e-06, 'epoch': 0.62}\n",
            "{'loss': 1.4315, 'learning_rate': 5.64e-06, 'epoch': 0.62}\n",
            "{'loss': 1.7303, 'learning_rate': 5.6118e-06, 'epoch': 0.62}\n",
            "{'loss': 1.7299, 'learning_rate': 5.5836e-06, 'epoch': 0.63}\n",
            "{'loss': 1.8471, 'learning_rate': 5.5554e-06, 'epoch': 0.63}\n",
            "{'loss': 1.8618, 'learning_rate': 5.5272e-06, 'epoch': 0.63}\n",
            "{'loss': 1.4525, 'learning_rate': 5.499e-06, 'epoch': 0.63}\n",
            "{'loss': 1.5235, 'learning_rate': 5.4708e-06, 'epoch': 0.64}\n",
            "{'loss': 1.7102, 'learning_rate': 5.4426e-06, 'epoch': 0.64}\n",
            "{'loss': 1.8543, 'learning_rate': 5.4144e-06, 'epoch': 0.64}\n",
            "{'loss': 1.4647, 'learning_rate': 5.3862e-06, 'epoch': 0.64}\n",
            "{'loss': 1.6504, 'learning_rate': 5.358e-06, 'epoch': 0.64}\n",
            "{'loss': 1.5857, 'learning_rate': 5.3298e-06, 'epoch': 0.65}\n",
            "{'loss': 1.843, 'learning_rate': 5.3016e-06, 'epoch': 0.65}\n",
            "{'loss': 1.5667, 'learning_rate': 5.2734e-06, 'epoch': 0.65}\n",
            "{'loss': 1.6217, 'learning_rate': 5.2452e-06, 'epoch': 0.65}\n",
            "{'loss': 1.6369, 'learning_rate': 5.217e-06, 'epoch': 0.65}\n",
            "{'loss': 1.5543, 'learning_rate': 5.1888e-06, 'epoch': 0.66}\n",
            "{'loss': 1.6679, 'learning_rate': 5.1606e-06, 'epoch': 0.66}\n",
            "{'loss': 1.6494, 'learning_rate': 5.1324e-06, 'epoch': 0.66}\n",
            "{'loss': 1.75, 'learning_rate': 5.1042e-06, 'epoch': 0.66}\n",
            "{'loss': 1.5974, 'learning_rate': 5.076e-06, 'epoch': 0.66}\n",
            "{'loss': 1.5627, 'learning_rate': 5.0478e-06, 'epoch': 0.67}\n",
            "{'loss': 1.366, 'learning_rate': 5.0196e-06, 'epoch': 0.67}\n",
            "{'loss': 1.5328, 'learning_rate': 4.9914e-06, 'epoch': 0.67}\n",
            "{'loss': 1.6077, 'learning_rate': 4.9632e-06, 'epoch': 0.67}\n",
            "{'loss': 1.6199, 'learning_rate': 4.935e-06, 'epoch': 0.67}\n",
            "{'loss': 1.6904, 'learning_rate': 4.9068e-06, 'epoch': 0.68}\n",
            "{'loss': 1.6282, 'learning_rate': 4.8786e-06, 'epoch': 0.68}\n",
            "{'loss': 1.5859, 'learning_rate': 4.8504e-06, 'epoch': 0.68}\n",
            "{'loss': 1.5189, 'learning_rate': 4.8222e-06, 'epoch': 0.68}\n",
            "{'loss': 1.483, 'learning_rate': 4.794e-06, 'epoch': 0.69}\n",
            "{'loss': 1.6526, 'learning_rate': 4.7658e-06, 'epoch': 0.69}\n",
            "{'loss': 1.4436, 'learning_rate': 4.7376e-06, 'epoch': 0.69}\n",
            "{'loss': 1.6839, 'learning_rate': 4.7094e-06, 'epoch': 0.69}\n",
            "{'loss': 1.7112, 'learning_rate': 4.6812e-06, 'epoch': 0.69}\n",
            "{'loss': 1.5859, 'learning_rate': 4.653e-06, 'epoch': 0.7}\n",
            "{'loss': 1.7402, 'learning_rate': 4.6248e-06, 'epoch': 0.7}\n",
            "{'loss': 1.6736, 'learning_rate': 4.5966e-06, 'epoch': 0.7}\n",
            "{'loss': 1.4957, 'learning_rate': 4.5684e-06, 'epoch': 0.7}\n",
            "{'loss': 1.6867, 'learning_rate': 4.5402e-06, 'epoch': 0.7}\n",
            "{'loss': 1.8845, 'learning_rate': 4.512e-06, 'epoch': 0.71}\n",
            "{'loss': 1.6604, 'learning_rate': 4.4838e-06, 'epoch': 0.71}\n",
            "{'loss': 1.5621, 'learning_rate': 4.4556e-06, 'epoch': 0.71}\n",
            "{'loss': 1.7851, 'learning_rate': 4.4274e-06, 'epoch': 0.71}\n",
            "{'loss': 1.5415, 'learning_rate': 4.3992e-06, 'epoch': 0.71}\n",
            "{'loss': 1.4323, 'learning_rate': 4.371e-06, 'epoch': 0.72}\n",
            "{'loss': 1.3795, 'learning_rate': 4.3428e-06, 'epoch': 0.72}\n",
            "{'loss': 1.5859, 'learning_rate': 4.3146e-06, 'epoch': 0.72}\n",
            "{'loss': 1.6952, 'learning_rate': 4.2864e-06, 'epoch': 0.72}\n",
            "{'loss': 2.058, 'learning_rate': 4.2582e-06, 'epoch': 0.72}\n",
            "{'loss': 1.6698, 'learning_rate': 4.23e-06, 'epoch': 0.73}\n",
            "{'loss': 1.7087, 'learning_rate': 4.2018e-06, 'epoch': 0.73}\n",
            "{'loss': 1.6427, 'learning_rate': 4.1736e-06, 'epoch': 0.73}\n",
            "{'loss': 1.7308, 'learning_rate': 4.1454e-06, 'epoch': 0.73}\n",
            "{'loss': 1.8377, 'learning_rate': 4.1172e-06, 'epoch': 0.73}\n",
            "{'loss': 1.5822, 'learning_rate': 4.089e-06, 'epoch': 0.74}\n",
            "{'loss': 1.5853, 'learning_rate': 4.0608e-06, 'epoch': 0.74}\n",
            "{'loss': 1.7099, 'learning_rate': 4.0326e-06, 'epoch': 0.74}\n",
            "{'loss': 1.7713, 'learning_rate': 4.0044e-06, 'epoch': 0.74}\n",
            "{'loss': 1.5737, 'learning_rate': 3.9762e-06, 'epoch': 0.75}\n",
            "{'loss': 1.5438, 'learning_rate': 3.948e-06, 'epoch': 0.75}\n",
            "{'loss': 1.644, 'learning_rate': 3.9198e-06, 'epoch': 0.75}\n",
            "{'loss': 1.465, 'learning_rate': 3.8916e-06, 'epoch': 0.75}\n",
            "{'loss': 1.6468, 'learning_rate': 3.8634e-06, 'epoch': 0.75}\n",
            "{'loss': 1.7467, 'learning_rate': 3.8352e-06, 'epoch': 0.76}\n",
            "{'loss': 1.6401, 'learning_rate': 3.8070000000000006e-06, 'epoch': 0.76}\n",
            "{'loss': 1.7076, 'learning_rate': 3.7788000000000006e-06, 'epoch': 0.76}\n",
            "{'loss': 1.7505, 'learning_rate': 3.7506e-06, 'epoch': 0.76}\n",
            "{'loss': 1.8582, 'learning_rate': 3.7224e-06, 'epoch': 0.76}\n",
            "{'loss': 1.6935, 'learning_rate': 3.6942e-06, 'epoch': 0.77}\n",
            "{'loss': 1.4609, 'learning_rate': 3.666e-06, 'epoch': 0.77}\n",
            "{'loss': 1.6735, 'learning_rate': 3.6378e-06, 'epoch': 0.77}\n",
            "{'loss': 1.865, 'learning_rate': 3.6096e-06, 'epoch': 0.77}\n",
            "{'loss': 1.6883, 'learning_rate': 3.5814e-06, 'epoch': 0.77}\n",
            "{'loss': 1.4405, 'learning_rate': 3.5532e-06, 'epoch': 0.78}\n",
            "{'loss': 1.6911, 'learning_rate': 3.525e-06, 'epoch': 0.78}\n",
            "{'loss': 1.6614, 'learning_rate': 3.4968e-06, 'epoch': 0.78}\n",
            "{'loss': 1.5512, 'learning_rate': 3.4686e-06, 'epoch': 0.78}\n",
            "{'loss': 1.8379, 'learning_rate': 3.4404e-06, 'epoch': 0.78}\n",
            "{'loss': 1.5168, 'learning_rate': 3.4122e-06, 'epoch': 0.79}\n",
            "{'loss': 1.8182, 'learning_rate': 3.384e-06, 'epoch': 0.79}\n",
            "{'loss': 1.8264, 'learning_rate': 3.3558e-06, 'epoch': 0.79}\n",
            "{'loss': 1.4648, 'learning_rate': 3.3276e-06, 'epoch': 0.79}\n",
            "{'loss': 1.7547, 'learning_rate': 3.2994e-06, 'epoch': 0.8}\n",
            "{'loss': 1.7415, 'learning_rate': 3.2712e-06, 'epoch': 0.8}\n",
            "{'loss': 1.5492, 'learning_rate': 3.243e-06, 'epoch': 0.8}\n",
            "{'loss': 1.6147, 'learning_rate': 3.2148e-06, 'epoch': 0.8}\n",
            "{'loss': 1.5987, 'learning_rate': 3.1866e-06, 'epoch': 0.8}\n",
            "{'loss': 1.7667, 'learning_rate': 3.1584e-06, 'epoch': 0.81}\n",
            "{'loss': 1.7424, 'learning_rate': 3.1302e-06, 'epoch': 0.81}\n",
            "{'loss': 1.5978, 'learning_rate': 3.102e-06, 'epoch': 0.81}\n",
            "{'loss': 1.604, 'learning_rate': 3.0738e-06, 'epoch': 0.81}\n",
            "{'loss': 1.4067, 'learning_rate': 3.0456e-06, 'epoch': 0.81}\n",
            "{'loss': 1.6598, 'learning_rate': 3.0174e-06, 'epoch': 0.82}\n",
            "{'loss': 1.6149, 'learning_rate': 2.9892e-06, 'epoch': 0.82}\n",
            "{'loss': 1.6888, 'learning_rate': 2.961e-06, 'epoch': 0.82}\n",
            "{'loss': 1.7667, 'learning_rate': 2.9328e-06, 'epoch': 0.82}\n",
            "{'loss': 1.6198, 'learning_rate': 2.9046e-06, 'epoch': 0.82}\n",
            "{'loss': 1.5665, 'learning_rate': 2.8764e-06, 'epoch': 0.83}\n",
            "{'loss': 1.8055, 'learning_rate': 2.8482e-06, 'epoch': 0.83}\n",
            "{'loss': 1.6466, 'learning_rate': 2.82e-06, 'epoch': 0.83}\n",
            "{'loss': 1.5135, 'learning_rate': 2.7918e-06, 'epoch': 0.83}\n",
            "{'loss': 1.5413, 'learning_rate': 2.7636e-06, 'epoch': 0.83}\n",
            "{'loss': 1.526, 'learning_rate': 2.7354e-06, 'epoch': 0.84}\n",
            "{'loss': 1.6232, 'learning_rate': 2.7072e-06, 'epoch': 0.84}\n",
            "{'loss': 1.5078, 'learning_rate': 2.679e-06, 'epoch': 0.84}\n",
            "{'loss': 1.6482, 'learning_rate': 2.6508e-06, 'epoch': 0.84}\n",
            "{'loss': 1.643, 'learning_rate': 2.6226e-06, 'epoch': 0.84}\n",
            "{'loss': 1.5999, 'learning_rate': 2.5944e-06, 'epoch': 0.85}\n",
            "{'loss': 1.5165, 'learning_rate': 2.5662e-06, 'epoch': 0.85}\n",
            "{'loss': 1.7989, 'learning_rate': 2.538e-06, 'epoch': 0.85}\n",
            "{'loss': 1.7817, 'learning_rate': 2.5098e-06, 'epoch': 0.85}\n",
            "{'loss': 1.5393, 'learning_rate': 2.4816e-06, 'epoch': 0.86}\n",
            "{'loss': 1.7602, 'learning_rate': 2.4534e-06, 'epoch': 0.86}\n",
            "{'loss': 1.5984, 'learning_rate': 2.4252e-06, 'epoch': 0.86}\n",
            "{'loss': 1.7008, 'learning_rate': 2.397e-06, 'epoch': 0.86}\n",
            "{'loss': 1.6834, 'learning_rate': 2.3688e-06, 'epoch': 0.86}\n",
            "{'loss': 1.6748, 'learning_rate': 2.3406e-06, 'epoch': 0.87}\n",
            "{'loss': 1.4254, 'learning_rate': 2.3124e-06, 'epoch': 0.87}\n",
            "{'loss': 1.5891, 'learning_rate': 2.2842e-06, 'epoch': 0.87}\n",
            "{'loss': 1.6453, 'learning_rate': 2.256e-06, 'epoch': 0.87}\n",
            "{'loss': 1.7156, 'learning_rate': 2.2278e-06, 'epoch': 0.87}\n",
            "{'loss': 1.62, 'learning_rate': 2.1996e-06, 'epoch': 0.88}\n",
            "{'loss': 1.7622, 'learning_rate': 2.1714e-06, 'epoch': 0.88}\n",
            "{'loss': 1.3725, 'learning_rate': 2.1432e-06, 'epoch': 0.88}\n",
            "{'loss': 1.6659, 'learning_rate': 2.115e-06, 'epoch': 0.88}\n",
            "{'loss': 1.7295, 'learning_rate': 2.0868e-06, 'epoch': 0.88}\n",
            "{'loss': 1.6983, 'learning_rate': 2.0586e-06, 'epoch': 0.89}\n",
            "{'loss': 1.678, 'learning_rate': 2.0304e-06, 'epoch': 0.89}\n",
            "{'loss': 1.6598, 'learning_rate': 2.0022e-06, 'epoch': 0.89}\n",
            "{'loss': 1.7373, 'learning_rate': 1.974e-06, 'epoch': 0.89}\n",
            "{'loss': 1.5266, 'learning_rate': 1.9458e-06, 'epoch': 0.89}\n",
            "{'loss': 1.6986, 'learning_rate': 1.9176e-06, 'epoch': 0.9}\n",
            "{'loss': 1.7748, 'learning_rate': 1.8894000000000003e-06, 'epoch': 0.9}\n",
            "{'loss': 1.8489, 'learning_rate': 1.8612e-06, 'epoch': 0.9}\n",
            "{'loss': 1.7728, 'learning_rate': 1.833e-06, 'epoch': 0.9}\n",
            "{'loss': 1.6092, 'learning_rate': 1.8048e-06, 'epoch': 0.91}\n",
            "{'loss': 1.7735, 'learning_rate': 1.7766e-06, 'epoch': 0.91}\n",
            "{'loss': 1.3876, 'learning_rate': 1.7484e-06, 'epoch': 0.91}\n",
            "{'loss': 1.427, 'learning_rate': 1.7202e-06, 'epoch': 0.91}\n",
            "{'loss': 1.8896, 'learning_rate': 1.692e-06, 'epoch': 0.91}\n",
            "{'loss': 1.6977, 'learning_rate': 1.6638e-06, 'epoch': 0.92}\n",
            "{'loss': 1.6108, 'learning_rate': 1.6356e-06, 'epoch': 0.92}\n",
            "{'loss': 1.4577, 'learning_rate': 1.6074e-06, 'epoch': 0.92}\n",
            "{'loss': 1.6791, 'learning_rate': 1.5792e-06, 'epoch': 0.92}\n",
            "{'loss': 1.5854, 'learning_rate': 1.551e-06, 'epoch': 0.92}\n",
            "{'loss': 1.8335, 'learning_rate': 1.5228e-06, 'epoch': 0.93}\n",
            "{'loss': 1.6097, 'learning_rate': 1.4946e-06, 'epoch': 0.93}\n",
            "{'loss': 1.7811, 'learning_rate': 1.4664e-06, 'epoch': 0.93}\n",
            "{'loss': 1.8579, 'learning_rate': 1.4382e-06, 'epoch': 0.93}\n",
            "{'loss': 1.4956, 'learning_rate': 1.41e-06, 'epoch': 0.93}\n",
            "{'loss': 1.7813, 'learning_rate': 1.3818e-06, 'epoch': 0.94}\n",
            "{'loss': 1.6387, 'learning_rate': 1.3536e-06, 'epoch': 0.94}\n",
            "{'loss': 1.6878, 'learning_rate': 1.3254e-06, 'epoch': 0.94}\n",
            "{'loss': 1.6091, 'learning_rate': 1.2972e-06, 'epoch': 0.94}\n",
            "{'loss': 1.6394, 'learning_rate': 1.269e-06, 'epoch': 0.94}\n",
            "{'loss': 1.6163, 'learning_rate': 1.2408e-06, 'epoch': 0.95}\n",
            "{'loss': 1.5364, 'learning_rate': 1.2126e-06, 'epoch': 0.95}\n",
            "{'loss': 1.7856, 'learning_rate': 1.1844e-06, 'epoch': 0.95}\n",
            "{'loss': 1.7272, 'learning_rate': 1.1562e-06, 'epoch': 0.95}\n",
            "{'loss': 1.4715, 'learning_rate': 1.128e-06, 'epoch': 0.95}\n",
            "{'loss': 1.549, 'learning_rate': 1.0998e-06, 'epoch': 0.96}\n",
            "{'loss': 1.4214, 'learning_rate': 1.0716e-06, 'epoch': 0.96}\n",
            "{'loss': 1.8528, 'learning_rate': 1.0434e-06, 'epoch': 0.96}\n",
            "{'loss': 1.788, 'learning_rate': 1.0152e-06, 'epoch': 0.96}\n",
            "{'loss': 1.683, 'learning_rate': 9.87e-07, 'epoch': 0.97}\n",
            "{'loss': 1.5268, 'learning_rate': 9.588e-07, 'epoch': 0.97}\n",
            "{'loss': 1.4817, 'learning_rate': 9.306e-07, 'epoch': 0.97}\n",
            "{'loss': 1.5706, 'learning_rate': 9.024e-07, 'epoch': 0.97}\n",
            "{'loss': 1.5314, 'learning_rate': 8.742e-07, 'epoch': 0.97}\n",
            "{'loss': 1.6122, 'learning_rate': 8.46e-07, 'epoch': 0.98}\n",
            "{'loss': 1.6712, 'learning_rate': 8.178e-07, 'epoch': 0.98}\n",
            "{'loss': 1.5199, 'learning_rate': 7.896e-07, 'epoch': 0.98}\n",
            "{'loss': 1.5825, 'learning_rate': 7.614e-07, 'epoch': 0.98}\n",
            "{'loss': 1.8298, 'learning_rate': 7.332e-07, 'epoch': 0.98}\n",
            "{'loss': 1.6113, 'learning_rate': 7.05e-07, 'epoch': 0.99}\n",
            "{'loss': 1.6337, 'learning_rate': 6.768e-07, 'epoch': 0.99}\n",
            "{'loss': 1.4409, 'learning_rate': 6.486e-07, 'epoch': 0.99}\n",
            "{'loss': 1.6725, 'learning_rate': 6.204e-07, 'epoch': 0.99}\n",
            "{'loss': 1.5171, 'learning_rate': 5.922e-07, 'epoch': 0.99}\n",
            "{'loss': 1.8741, 'learning_rate': 5.64e-07, 'epoch': 1.0}\n",
            "{'loss': 1.5979, 'learning_rate': 5.358e-07, 'epoch': 1.0}\n",
            "{'loss': 1.722, 'learning_rate': 5.076e-07, 'epoch': 1.0}\n",
            "{'loss': 1.5077, 'learning_rate': 4.794e-07, 'epoch': 1.0}\n",
            "{'loss': 1.5669, 'learning_rate': 4.512e-07, 'epoch': 1.0}\n",
            "{'loss': 1.5708, 'learning_rate': 4.23e-07, 'epoch': 1.01}\n",
            "{'loss': 1.6742, 'learning_rate': 3.948e-07, 'epoch': 1.01}\n",
            "{'loss': 1.5398, 'learning_rate': 3.666e-07, 'epoch': 1.01}\n",
            "{'loss': 1.7074, 'learning_rate': 3.384e-07, 'epoch': 1.01}\n",
            "{'loss': 1.7881, 'learning_rate': 3.102e-07, 'epoch': 1.02}\n",
            "{'loss': 1.5698, 'learning_rate': 2.82e-07, 'epoch': 1.02}\n",
            "{'loss': 1.6263, 'learning_rate': 2.538e-07, 'epoch': 1.02}\n",
            "{'loss': 1.413, 'learning_rate': 2.256e-07, 'epoch': 1.02}\n",
            "{'loss': 1.7247, 'learning_rate': 1.974e-07, 'epoch': 1.02}\n",
            "{'loss': 1.7177, 'learning_rate': 1.692e-07, 'epoch': 1.03}\n",
            "{'loss': 1.8367, 'learning_rate': 1.41e-07, 'epoch': 1.03}\n",
            "{'loss': 1.7541, 'learning_rate': 1.128e-07, 'epoch': 1.03}\n",
            "{'loss': 1.7308, 'learning_rate': 8.46e-08, 'epoch': 1.03}\n",
            "{'loss': 1.4632, 'learning_rate': 5.64e-08, 'epoch': 1.03}\n",
            "{'loss': 1.7445, 'learning_rate': 2.82e-08, 'epoch': 1.04}\n",
            "{'loss': 1.6338, 'learning_rate': 0.0, 'epoch': 1.04}\n",
            "{'train_runtime': 6809.3983, 'train_samples_per_second': 1.175, 'train_steps_per_second': 0.073, 'train_loss': 1.7332751612663269, 'epoch': 1.04}\n",
            "100% 500/500 [1:53:27<00:00, 13.61s/it]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▆▇▇▆▄▆▄▅▃▅▁▄▅▄▂▂▃▃▂▃▄▁▂▄▂▁▂▂▄▃▄▂▃▂▄▁▂▂▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 1.04\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 1.6338\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 6.907182121569485e+16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.73328\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 6809.3983\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 1.175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.073\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mresilient-spaceship-7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/utsa-it-phd/huggingface/runs/i0vt2qoe\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230725_213729-i0vt2qoe/logs\u001b[0m\n",
            "Exception in thread ChkStopThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 274, in check_stop_status\n",
            "    self._loop_check_status(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 212, in _loop_check_status\n",
            "    local_handle = request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 854, in deliver_stop_status\n",
            "    return self._deliver_stop_status(status)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 594, in _deliver_stop_status\n",
            "    return self._deliver_record(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 569, in _deliver_record\n",
            "    handle = mailbox._deliver_record(record, interface=self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
            "    interface._publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
            "    self._sock_client.send_record_publish(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
            "    self.send_server_request(server_req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
            "    self._send_message(msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
            "    self._sendall_with_error_handle(header + data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
            "    sent = self._sock.send(data)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3PGCA4zSdhid",
        "outputId": "4f9c704b-a026-4603-e9d1-9a784c641004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aXDjAycD-AYv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}